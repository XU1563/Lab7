{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimulating the data\n",
    "1>Start by writing some code to stimulate files containing random DNA,protein and binary data\n",
    "  - Using np.random.choice Using np.random.choice, generate 100 megabytes of random data containing 100%, 90%, 80%, 70%, 60%, and 50% zeros. \n",
    "  - The number of percentage of zeros determined by changing p values to 0 or 1\n",
    "  - Call np.packbits on the data before writing it to a file. \n",
    "  - Write the data to a file in home directory\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# Set 100% of zeros \n",
    "myvar1 = np.random.choice([0, 1], size=(8,1024,1024,100),replace=True, p=[1, 0])\n",
    "myvar1 = np.packbits(myvar1)\n",
    "\n",
    "#Set 90% of zeros \n",
    "myvar2 = np.random.choice([0, 1], size=(8,1024,1024,100), replace=True, p=[0.9, 0.1])\n",
    "myvar2 = np.packbits(myvar2)\n",
    "\n",
    "#Set 80% of zeros\n",
    "myvar3 = np.random.choice([0, 1], size=(8,1024,1024,100), replace=True, p=[0.8, 0.2])\n",
    "myvar3 = np.packbits(myvar3)\n",
    "\n",
    "#Set 70% of zeros\n",
    "myvar4 = np.random.choice([0, 1], size=(8,1024,1024,100), replace=True, p=[0.7, 0.3])\n",
    "myvar4 = np.packbits(myvar4)\n",
    "\n",
    "#Set 60% of zeros\n",
    "myvar5 = np.random.choice([0, 1], size=(8,1024,1024,100), replace=True, p=[0.6, 0.4])\n",
    "myvar5 = np.packbits(myvar5)\n",
    "\n",
    "#Set 50% of zeros\n",
    "myvar6 = np.random.choice([0, 1], size=(8,1024,1024,100), replace=True, p=[0.5, 0.5])\n",
    "myvar6 = np.packbits(myvar6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104857600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write into the home directory. \n",
    "open(\"zeros_100p\", \"wb\").write(myvar1)\n",
    "open(\"zeros_90p\", \"wb\").write(myvar2)\n",
    "open(\"zeros_80p\", \"wb\").write(myvar3)\n",
    "open(\"zeros_70p\", \"wb\").write(myvar4)\n",
    "open(\"zeros_60p\", \"wb\").write(myvar5)\n",
    "open(\"zeros_50p\", \"wb\").write(myvar6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After writing into the home directory, the output of the file is about 105MB for each case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate DNA and protein sequences 100 million letters long and write those to your home directory\n",
    "The process is similar as described above, but with different parameters. For the DNA sequence generation, the np.random choices becomes four types of nucleotide( A,T,C,G). and each letter would have equal probability.\n",
    "\n",
    "For the protein sequence, the random choices are 20 amino acids with equal probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seq= np.random.choice(['A', 'T','C','G'], size=100000000, replace=True, p=[0.25, 0.25,0.25,0.25])\n",
    "my_protein=np.random.choice(['A','R','N','D','C','E','Q','G','H','I','L','K','M','F','P','S','T','W','Y','V'], size=100000000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('nucleotide_seq','w').write(''.join(my_seq))\n",
    "open('protein_seq','w').write(''.join(my_protein))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing the data\n",
    "From the terminal to compress the data.\n",
    "- On each of the files generated above, run gzip, bzip, pbzip2 and ArithmeticCompress as follows:  \n",
    "time gzip –k file_name  \n",
    "time bzip2 –k file_name   \n",
    "time pbzip2 –k file_name  \n",
    "time ArithmeticCompress file_name \n",
    "\n",
    "- Keep track of the size of the input files, the size of the output files, and the time each command took to run in a table in your iPython notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result after the compress\n",
    "#### All the 0/1 input files size are 105MB, and the nucleotide and protein file size are 100MB \n",
    "\n",
    "#### 100% zeros\n",
    "time gzip -k zeros_100p  \n",
    "\n",
    "real    0m0.732s  \n",
    "user    0m0.696s  \n",
    "sys     0m0.036s  \n",
    "\n",
    "output file: 102kb\n",
    "\n",
    "time bzip2 -k zeros_100p\n",
    "\n",
    "real    0m1.017s  \n",
    "user    0m0.977s  \n",
    "sys     0m0.040s  \n",
    "\n",
    "output file:113b\n",
    "\n",
    "time pbzip2 -k zeros_100p\n",
    "\n",
    "real    0m0.108s  \n",
    "user    0m1.947s  \n",
    "sys     0m0.113s  \n",
    "\n",
    "output file:5.62kb\n",
    "    \n",
    "time ArithmeticCompress zeros_100p zeros_100p.art\n",
    "\n",
    "real    0m14.886s  \n",
    "user    0m14.830s  \n",
    "sys     0m0.056s   \n",
    "\n",
    "output file:1.03kb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 90% zeros\n",
    "time gzip -k zeros_90p\n",
    "\n",
    "real    0m19.091s  \n",
    "user    0m18.938s  \n",
    "sys     0m0.152s\n",
    "\n",
    "output file:58.7MB\n",
    "\n",
    "time bzip2 -k zeros_90p\n",
    "\n",
    "real    0m10.638s  \n",
    "user    0m10.569s  \n",
    "sys     0m0.068s\n",
    "\n",
    "output file:61.2MB\n",
    "\n",
    "time pbzip2 -k zeros_90p\n",
    "\n",
    "real    0m0.785s  \n",
    "user    0m18.999s  \n",
    "sys     0m0.994s\n",
    "\n",
    "output file:61.2MB\n",
    "\n",
    "time ArithmeticCompress zeros_90p zeros_90p.art\n",
    "\n",
    "real    0m28.906s  \n",
    "user    0m28.706s  \n",
    "sys     0m0.200s\n",
    "\n",
    "output file:49.2MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80% zeros\n",
    "time gzip -k zeros_80p\n",
    "\n",
    "real    0m14.080s  \n",
    "user    0m13.925s  \n",
    "sys     0m0.128s\n",
    "\n",
    "output file:81.2MB\n",
    "    \n",
    "time bzip2 -k zeros_80p\n",
    "\n",
    "real    0m11.990s  \n",
    "user    0m11.894s  \n",
    "sys     0m0.096s\n",
    "\n",
    "output file:86.6MB\n",
    "\n",
    "time pbzip2 -k zeros_80p\n",
    "\n",
    "real    0m0.956s  \n",
    "user    0m23.806s  \n",
    "sys     0m0.938s\n",
    "\n",
    "output file:86.7MB\n",
    "\n",
    "time ArithmeticCompress zeros_80p zeros_80p.art\n",
    "\n",
    "real    0m35.604s  \n",
    "user    0m35.359s  \n",
    "sys     0m0.212s\n",
    "\n",
    "output file:75.7MB\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70% zeros\n",
    "time gzip -k zeros_70p\n",
    "\n",
    "real    0m6.078s  \n",
    "user    0m5.937s  \n",
    "sys     0m0.140s\n",
    "\n",
    "output file:93.6MB\n",
    "    \n",
    "time bzip2 -k zeros_70p\n",
    "\n",
    "real    0m13.738s  \n",
    "user    0m13.642s  \n",
    "sys     0m0.096s\n",
    "\n",
    "output file:99.8MB\n",
    "\n",
    "time pbzip2 -k zeros_70p\n",
    "\n",
    "real    0m1.145s  \n",
    "user    0m29.959s  \n",
    "sys     0m0.887s\n",
    "\n",
    "output file:99.8MB\n",
    "    \n",
    "time ArithmeticCompress zeros_70p zeros_70p.art\n",
    "\n",
    "real    0m39.585s  \n",
    "user    0m39.299s  \n",
    "sys     0m0.237s\n",
    "\n",
    "output file:92.4MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 60% zeros\n",
    "time gzip -k zeros_60p\n",
    "\n",
    "real    0m4.247s  \n",
    "user    0m4.179s  \n",
    "sys     0m0.069s\n",
    "\n",
    "output file:102MB\n",
    "    \n",
    "time bzip2 -k zeros_60p\n",
    "\n",
    "real    0m15.710s  \n",
    "user    0m15.605s  \n",
    "sys     0m0.104s\n",
    "\n",
    "output file:105MB\n",
    "\n",
    "time pbzip2 -k zeros_60p\n",
    "\n",
    "real    0m1.387s  \n",
    "user    0m37.009s  \n",
    "sys     0m0.856s\n",
    "\n",
    "output file:105MB\n",
    "\n",
    "time ArithmeticCompress zeros_60p zeros_60p.art\n",
    "\n",
    "real    0m40.953s  \n",
    "user    0m40.648s  \n",
    "sys     0m0.280s\n",
    "\n",
    "output file:102MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50% zeros\n",
    "time gzip -k zeros_50p\n",
    "\n",
    "real    0m3.503s  \n",
    "user    0m3.434s  \n",
    "sys     0m0.068s\n",
    "\n",
    "output file:105MB\n",
    "\n",
    "time bzip2 -k zeros_50p\n",
    "\n",
    "real    0m16.669s  \n",
    "user    0m16.544s  \n",
    "sys     0m0.125s\n",
    "\n",
    "output file:105MB\n",
    "    \n",
    "time pbzip2 -k zeros_50p\n",
    "\n",
    "real    0m1.532s  \n",
    "user    0m40.325s  \n",
    "sys     0m0.937s\n",
    "\n",
    "output file:105MB\n",
    "    \n",
    "time ArithmeticCompress zeros_50p zeros_50p.art\n",
    "\n",
    "real    0m40.867s  \n",
    "user    0m40.654s  \n",
    "sys     0m0.213s  \n",
    "\n",
    "output file:105MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nucleotide sequence\n",
    "time gzip -k nucleotide_seq\n",
    "\n",
    "real    0m12.158s  \n",
    "user    0m12.057s  \n",
    "sys     0m0.101s  \n",
    "\n",
    "output file:29.2 MB\n",
    "\n",
    "time bzip2 -k nucleotide_seq\n",
    "\n",
    "real    0m9.474s  \n",
    "user    0m9.426s  \n",
    "sys     0m0.048s  \n",
    "\n",
    "output file:27.3 MB\n",
    "\n",
    "time pbzip2 -k nucleotide_seq\n",
    "\n",
    "real    0m0.679s  \n",
    "user    0m16.024s  \n",
    "sys     0m0.842s  \n",
    "\n",
    "output file:27.3 MB\n",
    "\n",
    "time ArithmeticCompress nucleotide_seq nucleotide_seq.art\n",
    "\n",
    "real    0m21.268s  \n",
    "user    0m21.191s  \n",
    "sys     0m0.076s  \n",
    "\n",
    "output file:25 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protein sequence\n",
    "time gzip -k protein_seq\n",
    "\n",
    "real    0m4.211s  \n",
    "user    0m4.154s  \n",
    "sys     0m0.057s\n",
    "\n",
    "output file:60.6 MB\n",
    "    \n",
    "time bzip2 -k protein_seq\n",
    "\n",
    "real    0m9.956s  \n",
    "user    0m9.895s  \n",
    "sys     0m0.060s\n",
    "\n",
    "output file:55.3 MB\n",
    "    \n",
    "time pbzip2 -k protein_seq\n",
    "\n",
    "real    0m0.773s  \n",
    "user    0m18.709s  \n",
    "sys     0m0.737s\n",
    "\n",
    "output file:55.3 MB\n",
    "\n",
    "time ArithmeticCompress protein_seq protein_seq.art\n",
    "\n",
    "real    0m29.594s  \n",
    "user    0m29.404s  \n",
    "sys     0m0.189s\n",
    "\n",
    "output file:54 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            File output size and compression time            \n",
      "              \n",
      "Compression     gzip        bzip2       pbzip2      Arithmetic\n",
      "              \n",
      "100%           102 KB      113 B        5.62 KB      1.03 KB\n",
      "               0.732s      1.017s       0.108s       14.886s\n",
      "              \n",
      "90%            58.7 MB     61.2 MB      61.2 MB      49.2MB\n",
      "               19.091s     10.638s      0.785s       28.906s\n",
      "              \n",
      "80%            81.2 MB     86.6 MB      86.7 MB      75.7 MB\n",
      "               14.080s     11.990s      0.956s       35.604s\n",
      "              \n",
      "70%            93.6 MB     99.8 MB      99.8 MB      92.4 MB\n",
      "               6.078s      13.738s      1.145s       39.585s\n",
      "              \n",
      "60%            102 MB      105 MB       105 MB       102 MB\n",
      "               4.247s      15.710s      1.387s       40.953s\n",
      "              \n",
      "50%            105 MB      105 MB       105 MB       105 MB\n",
      "               3.503s      16.669s      1.532s       40.867s\n",
      "              \n",
      "nucleotide     29.2 MB      27.3 MB      27.3 MB      25 MB\n",
      "               12.158s      9.474s       0.679s       21.268s\n",
      "              \n",
      "protein        60.6 MB      55.3 MB      55.3 MB      54 MB\n",
      "               4.211s       9.956s       0.773s       29.594s\n"
     ]
    }
   ],
   "source": [
    "print(\"            File output size and compression time            \")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"Compression     gzip        bzip2       pbzip2      Arithmetic\")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"100%           102 KB      113 B        5.62 KB      1.03 KB\")\n",
    "\n",
    "print(\"               0.732s      1.017s       0.108s       14.886s\")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"90%            58.7 MB     61.2 MB      61.2 MB      49.2MB\")\n",
    "\n",
    "print(\"               19.091s     10.638s      0.785s       28.906s\")\n",
    "\n",
    "print(\"              \")\n",
    "  \n",
    "print(\"80%            81.2 MB     86.6 MB      86.7 MB      75.7 MB\")\n",
    "\n",
    "print(\"               14.080s     11.990s      0.956s       35.604s\")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"70%            93.6 MB     99.8 MB      99.8 MB      92.4 MB\")\n",
    "\n",
    "print(\"               6.078s      13.738s      1.145s       39.585s\")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"60%            102 MB      105 MB       105 MB       102 MB\")\n",
    "\n",
    "print(\"               4.247s      15.710s      1.387s       40.953s\")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"50%            105 MB      105 MB       105 MB       105 MB\")\n",
    "\n",
    "print(\"               3.503s      16.669s      1.532s       40.867s\")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"nucleotide     29.2 MB      27.3 MB      27.3 MB      25 MB\")\n",
    "\n",
    "print(\"               12.158s      9.474s       0.679s       21.268s\")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"protein        60.6 MB      55.3 MB      55.3 MB      54 MB\")\n",
    "\n",
    "print(\"               4.211s       9.956s       0.773s       29.594s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "##### -Which algorithm achieves the best level of compression on each file type?  \n",
    "\n",
    "The best level of the compression is achieved under the Arithmetic algorithm for all the cases. Since it has the the smallest output file size. \n",
    "\n",
    "##### -Which algorithm is the fastest?  \n",
    "\n",
    "pbzip2 algorithm is the fastest overall. The most files get compressed within and around 1 second. \n",
    "\n",
    "##### -What is the difference between bzip2 and pbzip2? Do you expect one to be faster and why?  \n",
    "\n",
    "Both Bzip2 and pbzip2 will compress the file and produce a new file with the extension .bz2. But,bzip2 compresses data in blocks of size between 100 and 900 kB and uses the Burrows–Wheeler transform to convert frequently-recurring character sequences into strings of identical letters. \n",
    "\n",
    "pbzip2 have multi-cores and looking for a file compressing utility that uses all the available CPU cores ( significantly improving the performance & reducing the time it takes) \n",
    "So, from the time prespective, the pbzip2 is much faster than the Bzip2.\n",
    "\n",
    "##### -How does the level of compression change as the percentage of zeros increases? Why does this happen?\n",
    "\n",
    "As the file containing the percentage of zeros increases, the level of compression decreases, the file compressed size is smaller and the compression time is less as well. This is because there more zeros in the file, it takes up less percentaage of file.\n",
    "##### -What is the minimum number of bits required to store a single DNA base?\n",
    "\n",
    "2 bits \n",
    "\n",
    "##### -What is the minimum number of bits required to store an amino acid letter?\n",
    "\n",
    "Theoretically, for an amino acid letter we need log2(20) which is about of 4.32 bits. and round up to 5 bits\n",
    "\n",
    "#### -In your tests, how many bits did gzip and bzip2 actually require to store your random DNA and protein sequences?\n",
    "\n",
    "Random DNA compressed in gzip file requires 29.2 MB, (using the convertion unit 8 bits/byte * 1024 bytes/kilobyte * 1024 kilobytes/megabyte * 100) = 2449473536 bits\n",
    "\n",
    "Using the convertion factor above, bzip2 file is 27.3 MB (2290089984 bits)\n",
    "\n",
    "Random protein sequence compressed in gzip file is 60.6 MB (5083496448 bits)\n",
    "                      in bzip2 file is 55.3 MB (4638900224 bits)\n",
    "##### -Are gzip and bzip2 performing well on DNA and proteins?\n",
    "For the DNA compression, the file can be compressed from 100MB to 20MB. the protein compression is from 100MB to 60MB. The compression time for DNA under the bip2 is less than the time compression used in protein. On the oppposite, the gzip is fast for the protein sequence compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress the real data\n",
    "1>Find the nucleic acid sequences of gp120 homologs from at least  10 different HIV isolates and concatenate them together into a single multi-FASTA.\n",
    "\n",
    "2> Compress the multi-FASTA using gzip, bzip2, and arithmetic coding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10069"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "Seq=[]\n",
    "New=[]\n",
    "Entrez.email=\"zihuixu1@berkeley.edu\"\n",
    "handle=Entrez.esearch(db='nucleotide',\n",
    "                     term='gp120',\n",
    "                     sort='relevance',\n",
    "                     idtype='acc')\n",
    "\n",
    "for i in Entrez.read(handle)['IdList']:\n",
    "    handle=Entrez.efetch(db='nucleotide',id=i,rettype='fasta',retmode='text')\n",
    "    temp=SeqIO.read(handle,'fasta')\n",
    "    Seq.append(\">\" + temp.description + '\\n' + str(temp.seq) + '\\n')\n",
    "\n",
    "open('gp120.fa','w').write(''.join(str(Seq)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The result of compress file \n",
    "time gzip -k gp120.fa\n",
    "\n",
    "real    0m0.004s  \n",
    "user    0m0.000s  \n",
    "sys     0m0.003s  \n",
    "output file: 1.88kb\n",
    "    \n",
    "time bzip2 -k gp120.fa\n",
    "\n",
    "real    0m0.006s  \n",
    "user    0m0.003s  \n",
    "sys     0m0.003s  \n",
    "output file: 1.91kb\n",
    "    \n",
    "time pbzip2 -k gp120.fa\n",
    "\n",
    "real    0m0.008s  \n",
    "user    0m0.004s  \n",
    "sys     0m0.004s  \n",
    "output file: 1.91kb\n",
    "    \n",
    "time ArithmeticCompress gp120.fa gp120.fa.art\n",
    "\n",
    "real    0m0.010s  \n",
    "user    0m0.010s  \n",
    "sys     0m0.000s  \n",
    "output file: 3.04kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           File output size and compression time for HIV gp120 multi-FASTA               \n",
      "              \n",
      "Compression                                 gzip        bzip2         pbzip2       Arithmetic\n",
      "              \n",
      "Run output file size                        1.88 KB      1.91KB        1.91 KB      3.04 KB\n",
      "              \n",
      "Real running time                           0.004s       0.006s        0.008s       0.01s\n",
      "              \n",
      "Real compression data ratio                 0.22         0.21          0.226        0.36\n",
      "              \n",
      "random compression data ratio               0.29         0.27          0.27         0.25\n"
     ]
    }
   ],
   "source": [
    "# The initial file is 8.44kb\n",
    "print(\"           File output size and compression time for HIV gp120 multi-FASTA               \")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"Compression                                 gzip        bzip2         pbzip2       Arithmetic\")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"Run output file size                        1.88 KB      1.91KB        1.91 KB      3.04 KB\")\n",
    "\n",
    "print(\"              \")\n",
    "\n",
    "print(\"Real running time                           0.004s       0.006s        0.008s       0.01s\")\n",
    "print(\"              \")\n",
    "\n",
    "print(\"Real compression data ratio                 0.22         0.21          0.226        0.36\")\n",
    "print(\"              \")\n",
    "\n",
    "print(\"random compression data ratio               0.29         0.27          0.27         0.25\")\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "    \n",
    "    Compressing the real data is much better than compressing the random data. This may because that the real data with different fasta sequence that are really similar and the mutual information contain is high which save some bites during the compression. The random data is uniform distribution.\n",
    "    \n",
    "    After comparing the compression ratio between the file output and input size, the ratio within the real data is less than the random data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating compression of 1000 terabytes\n",
    "Most of the data, say 80%, is re-sequencing of genomes and plasmids that are very similar to each other. Another 10% might be protein sequences, and the last 10% are binary microscope\n",
    "images which we’ll assume follow the worst-case scenario of being completely random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resequncing genome and plasmids:\n",
    "    Using the gzip algothrim in this case, the file can be compressed into the smaller file since the sequences are really similar to each other. gzip can also compress the file in the fast rate. After the compression, 60% of bit can be saved.\n",
    "    \n",
    "protein sequence:\n",
    "    for the protein compression, I decided to use the pbzip algorithm, since it can compress the file fast and into the small size. it may be about 70 % storage can be saved.\n",
    "    \n",
    "microscope image:\n",
    "    the information contain is really random. using the arithmetic compression to achieve the better result.As long as the time is not a big consideration, the compressed file can save up to 80%.\n",
    "    \n",
    "MAYBE if the compressed file can achieve 1% reduction in overall data, that can provide me $500 saving. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
